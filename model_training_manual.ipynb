{"cells":[{"metadata":{"_uuid":"9886d6f9-4077-4462-a63c-5304c892294f","_cell_guid":"3d9f4483-9a26-4279-a66b-a9e969bdb871","trusted":true},"cell_type":"code","source":"from transformers import MT5ForConditionalGeneration as MT5Model\nfrom transformers import AdamW\nfrom transformers import MT5Tokenizer\nimport torch\nfrom torch.optim import Adam, lr_scheduler\nimport pickle","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MT5Model.from_pretrained(\"google/mt5-small\")\nmodel.train()\ntokenizer = MT5Tokenizer.from_pretrained('google/mt5-small')\noptimizer = AdamW(model.parameters(), lr=0.00001)\nprint(\"Number of parameters: \", model.num_parameters())","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77fcd5a15cae415e92ced574259104d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c32900e04ae84fdda4c9f49927aaba02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b685bea60f4c43628451dbfea8392692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7afa7b0d8ed488d937b1b3c70affb5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/82.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc4df4b3c3e54610b8ef65e06aa4a081"}},"metadata":{}},{"output_type":"stream","text":"Number of parameters:  300176768\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"/kaggle/input/tolokadialogues/prepared_dialogueCR.pickle\", 'rb') as file:\n    dialogues = pickle.load(file)\n\n# even stands for even number of repliques in one dialog, so each U1 replique has an answer\ndialogues_even = list(map(lambda x: x[:-1] if len(x) % 2 == 1 else x, dialogues))\ndialogues_even_flatten = [replique for dialogue in dialogues for replique in dialogue]\nrepliquesU1 = list(filter(lambda x: x.startswith(\"USER1:\"), dialogues_even_flatten))\nrepliquesU2 = list(filter(lambda x: x.startswith(\"USER2:\"), dialogues_even_flatten))","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = tokenizer.prepare_seq2seq_batch(src_texts=repliquesU1[:500], tgt_texts=repliquesU2[:500], return_tensors=\"pt\", padding=True)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(\"cuda\")\ndata = data.to(\"cuda\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(model.parameters())\nscheduler = lr_scheduler.StepLR(optimizer, 160, gamma=0.5, last_epoch=-1, verbose=False)\ntrain_loss = 5\nbatch = 4\nfor epoch in range(20):\n    model.train()\n    for i in range(80):\n        output = model(input_ids = data.input_ids[i*batch:(i+1)*batch], labels = data.labels[i*batch:(i+1)*batch])\n        train_loss = 0.95 * train_loss + 0.05 * output.loss.item()\n        output.loss.backward()\n        optimizer.step()\n        scheduler.step()\n    \n    model.eval()\n    val_output = model(input_ids = data.input_ids[400:405], labels = data.labels[400:405])\n    val_loss = output.loss\n        \n    print(f\"Epoch {epoch}: Train loss {train_loss}  Validation loss {val_loss}\")","execution_count":9,"outputs":[{"output_type":"stream","text":"Epoch 0: Train loss 2.6786779819147175  Validation loss 1.6937686204910278\nEpoch 1: Train loss 2.7783465729119756  Validation loss 2.787876844406128\nEpoch 2: Train loss 2.414172465153645  Validation loss 1.4324270486831665\nEpoch 3: Train loss 2.460768471373204  Validation loss 1.3552175760269165\nEpoch 4: Train loss 2.0129902701916014  Validation loss 1.126721978187561\nEpoch 5: Train loss 1.8126689059359882  Validation loss 1.1642115116119385\nEpoch 6: Train loss 1.6951650629713282  Validation loss 1.0683342218399048\nEpoch 7: Train loss 1.672895834421422  Validation loss 0.9744287133216858\nEpoch 8: Train loss 1.6667012834370414  Validation loss 0.9239241480827332\nEpoch 9: Train loss 1.6130789237413314  Validation loss 0.9025110006332397\nEpoch 10: Train loss 1.5773308704127742  Validation loss 0.8895124793052673\nEpoch 11: Train loss 1.5408974707502643  Validation loss 0.8862259387969971\nEpoch 12: Train loss 1.5257928335701434  Validation loss 0.8606579899787903\nEpoch 13: Train loss 1.52435249261763  Validation loss 0.8879380226135254\nEpoch 14: Train loss 1.5205637143566249  Validation loss 0.8958179354667664\nEpoch 15: Train loss 1.5150057174880862  Validation loss 1.0483421087265015\nEpoch 16: Train loss 1.5116266130460227  Validation loss 0.9367542862892151\nEpoch 17: Train loss 1.5225675142493265  Validation loss 0.9859237670898438\nEpoch 18: Train loss 1.5193629359725387  Validation loss 0.954203724861145\nEpoch 19: Train loss 1.5021335878649125  Validation loss 0.8726123571395874\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(\"cpu\")","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_input = tokenizer.encode(repliquesU1[1], add_special_tokens=False, return_tensors='pt')\nresult_ids = model.generate(model_input, max_length=250, do_sample=True, top_p=0.95, top_k=60)\nresult_tokens = tokenizer.convert_ids_to_tokens(result_ids[0])\nresult_string = tokenizer.convert_tokens_to_string(result_tokens)\nprint(result_string)","execution_count":18,"outputs":[{"output_type":"stream","text":"<pad> ?<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> USER2 не не<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_pretrained('models/mt5small/')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}